{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PKM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Afrizal2609/Hate-Speech-Detection-of-banjar-Languange/blob/main/Colab/hate%20speech%20classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Library**"
      ],
      "metadata": {
        "id": "oG36tvtuq3Ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaM3qRJZx_Ic",
        "outputId": "385eeba8-0bed-4ed0-89cb-7630d8935ef6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import spacy\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import gensim\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "!python -m spacy download en_core_web_md\n",
        "nlp = spacy.load(\"en_core_web_md\")"
      ],
      "metadata": {
        "id": "8QOg4Kq4iWec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc11f617-5a71-45b8-90d0-9501c60f1ee8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.4.0/en_core_web_md-3.4.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.8 MB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-md==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (21.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (4.64.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (1.9.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (3.0.6)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (1.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Dataset**"
      ],
      "metadata": {
        "id": "g17nvAfpq9ER"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mxv0yvbJmbs9",
        "outputId": "4591d84d-bdbe-4d26-c0f4-20550a72da87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text Label\n",
              "0  bayangkan kalau kadada cctv warga nang dijebak...     0\n",
              "1                             sagan apa naik pangkat     0\n",
              "2  ini hanyar nang ketahuan balum lagi nang kada ...     0\n",
              "3      handak komen tapi takutan jadi target mbah ni     0\n",
              "4        Kaini banar menyasah target nya oknum oknum     0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0824bf97-f92f-4bb5-954e-9d15d5872bed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bayangkan kalau kadada cctv warga nang dijebak...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sagan apa naik pangkat</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ini hanyar nang ketahuan balum lagi nang kada ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>handak komen tapi takutan jadi target mbah ni</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kaini banar menyasah target nya oknum oknum</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0824bf97-f92f-4bb5-954e-9d15d5872bed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0824bf97-f92f-4bb5-954e-9d15d5872bed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0824bf97-f92f-4bb5-954e-9d15d5872bed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Upload Dataset\n",
        "#load dataset\n",
        "df = pd.read_csv('/content/banjar.csv')\n",
        "\n",
        "# preview of dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preparing Dataset**"
      ],
      "metadata": {
        "id": "ErQPQ4NkrF2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rename columns\n",
        "df.columns = ['Text', 'Label']\n",
        "\n",
        "# remove missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# encode target label\n",
        "le = LabelEncoder()\n",
        "df['Label'] = le.fit_transform(df['Label'])\n",
        "\n",
        "# establish input and output\n",
        "X = list(df['Text'])\n",
        "y = list(df['Label'])\n",
        "\n"
      ],
      "metadata": {
        "id": "tPV5azu7pKef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f27944-27da-4711-fb4d-821aa3becb19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Custom Class for GloveVectorizer\n",
        "class GloveVectorizer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, model_name=\"en_core_web_md\"):\n",
        "        self._nlp = spacy.load(model_name)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.concatenate(\n",
        "            [self._nlp(doc).vector.reshape(1, -1) for doc in X]\n",
        "        )"
      ],
      "metadata": {
        "id": "SUByDbFkLJy5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Naive Bayes**\n"
      ],
      "metadata": {
        "id": "8xBwCb2gW_UA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes with Word N-Gram**"
      ],
      "metadata": {
        "id": "XHXOkevGXHA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "cv = CountVectorizer(analyzer = 'word',ngram_range=(1,1), stop_words='english')\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)"
      ],
      "metadata": {
        "id": "pY81CYRUpYjO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MultinomialNB()\n",
        "clf.fit(X_train_cv, y_train)\n",
        "# create predictions\n",
        "y_pred = clf.predict(X_test_cv)\n",
        "\n",
        "# find f-1 score\n",
        "score = f1_score(y_test, y_pred, average='micro')\n",
        "print('F-1 score : {}'.format(np.round(score,4)))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "test_text=cv.transform([\"bungul siapa nyawa ngini\"])\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Prediction:\")\n",
        "print(clf.predict(test_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM6ptJC3pcNO",
        "outputId": "f138a8f3-ed84-407b-a4a2-aea183525cf6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-1 score : 0.9064\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.99      0.95      2697\n",
            "           1       0.81      0.32      0.46       380\n",
            "\n",
            "    accuracy                           0.91      3077\n",
            "   macro avg       0.86      0.65      0.70      3077\n",
            "weighted avg       0.90      0.91      0.89      3077\n",
            "\n",
            "confusion matrix:\n",
            "[[2668   29]\n",
            " [ 259  121]]\n",
            "\n",
            "\n",
            "Prediction:\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes with TF-IDF**"
      ],
      "metadata": {
        "id": "bDSjqm35ajP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TFIDF\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_train = tfidf.fit_transform(X_train)\n",
        "#Fitting and transforming input data\n",
        "tfidf_train = tfidf.transform(X_train)\n",
        "tfidf_test = tfidf.transform(X_test)"
      ],
      "metadata": {
        "id": "VpO32Qnpamfl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MultinomialNB()\n",
        "clf.fit(tfidf_train, y_train)\n",
        "# create predictions\n",
        "y_pred = clf.predict(tfidf_test)\n",
        "\n",
        "# find f-1 score\n",
        "score = f1_score(y_test, y_pred, average='micro')\n",
        "print('F-1 score : {}'.format(np.round(score,4)))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "test_text=tfidf.transform([\"bungul siapa nyawa ngini\"])\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Prediction:\")\n",
        "print(clf.predict(test_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEmAfzKwamoE",
        "outputId": "9dfd0b6a-e918-41c8-af14-982a0f9bbd10"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-1 score : 0.896\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94      2697\n",
            "           1       1.00      0.16      0.27       380\n",
            "\n",
            "    accuracy                           0.90      3077\n",
            "   macro avg       0.95      0.58      0.61      3077\n",
            "weighted avg       0.91      0.90      0.86      3077\n",
            "\n",
            "confusion matrix:\n",
            "[[2697    0]\n",
            " [ 320   60]]\n",
            "\n",
            "\n",
            "Prediction:\n",
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes with Word N-Gram and TF-IDF**"
      ],
      "metadata": {
        "id": "W1DvkdBMfBVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tfidf = TfidfVectorizer(min_df=5, ngram_range=(1, 1))\n",
        "tfidf_features = Tfidf.fit_transform(df.Text)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, df[\"Label\"], test_size = 1/5, random_state = 50)"
      ],
      "metadata": {
        "id": "c13Xt-FYfIWO"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "# create predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# find f-1 score\n",
        "score = f1_score(y_test, y_pred, average='micro')\n",
        "print('F-1 score : {}'.format(np.round(score,4)))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "test_text=Tfidf.transform([\"bungul siapa nyawa ngini\"])\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Prediction:\")\n",
        "print(clf.predict(test_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajsEbDaYfIif",
        "outputId": "67ea63af-9e66-4805-f4a2-c4e6d883cdaa"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-1 score : 0.8963\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94      2657\n",
            "           1       0.95      0.25      0.40       420\n",
            "\n",
            "    accuracy                           0.90      3077\n",
            "   macro avg       0.92      0.63      0.67      3077\n",
            "weighted avg       0.90      0.90      0.87      3077\n",
            "\n",
            "confusion matrix:\n",
            "[[2651    6]\n",
            " [ 313  107]]\n",
            "\n",
            "\n",
            "Prediction:\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes with Word2Vec**"
      ],
      "metadata": {
        "id": "e8BDy6qvuZxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "w2v_model = gensim.models.Word2Vec(X_train, vector_size=100, window=5, min_count=2)\n",
        "\n",
        "words = set(w2v_model.wv.index_to_key )\n",
        "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
        "                         for ls in X_train])\n",
        "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
        "                         for ls in X_test])\n",
        "\n",
        "# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n",
        "X_train_vect_avg = []\n",
        "for v in X_train_vect:\n",
        "    if v.size:\n",
        "        X_train_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
        "        \n",
        "X_test_vect_avg = []\n",
        "for v in X_test_vect:\n",
        "    if v.size:\n",
        "        X_test_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_test_vect_avg.append(np.zeros(100, dtype=float))"
      ],
      "metadata": {
        "id": "PectJBAYuqod",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "529e63ae-9065-4474-ca3e-6effe9965db0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = GaussianNB()\n",
        "clf.fit(X_train_vect_avg, y_train)\n",
        "# create predictions\n",
        "y_pred = clf.predict(X_test_vect_avg)\n",
        "\n",
        "# find f-1 score\n",
        "score = f1_score(y_test, y_pred, average='micro')\n",
        "print('F-1 score : {}'.format(np.round(score,4)))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "test_text=([\"tambuk siapa nyawa ngini\"])\n",
        "test_text_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
        "                         for ls in test_text])\n",
        "test_text_avg = []\n",
        "for v in test_text_vect:\n",
        "    if v.size:\n",
        "        test_text_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        test_text_avg.append(np.zeros(100, dtype=float))\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Prediction:\")\n",
        "print(clf.predict(test_text_avg))"
      ],
      "metadata": {
        "id": "8YOKo4MMvEMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a08f7e2-3571-4ff6-fa51-9e7d53165df2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-1 score : 0.7764\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.84      0.87      2697\n",
            "           1       0.22      0.33      0.27       380\n",
            "\n",
            "    accuracy                           0.78      3077\n",
            "   macro avg       0.56      0.58      0.57      3077\n",
            "weighted avg       0.82      0.78      0.79      3077\n",
            "\n",
            "confusion matrix:\n",
            "[[2264  433]\n",
            " [ 255  125]]\n",
            "\n",
            "\n",
            "Prediction:\n",
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes with Glove**"
      ],
      "metadata": {
        "id": "PJkTfE89Ni-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "g = GloveVectorizer()\n",
        "nb = GaussianNB()\n",
        "\n",
        "pipeline = make_pipeline(g, nb)\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "score = f1_score(y_test, y_pred, average='micro')\n",
        "print('F-1 score : {}'.format(np.round(score,4)))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "test_text=([\"siapa nyawa ngini\"])\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Prediction:\")\n",
        "print(pipeline.predict(test_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95W-KeasNpso",
        "outputId": "f2ba4e61-a979-4766-d0e9-92652b0426d7"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-1 score : 0.416\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.37      0.53      2697\n",
            "           1       0.14      0.74      0.24       380\n",
            "\n",
            "    accuracy                           0.42      3077\n",
            "   macro avg       0.53      0.55      0.38      3077\n",
            "weighted avg       0.81      0.42      0.49      3077\n",
            "\n",
            "confusion matrix:\n",
            "[[1000 1697]\n",
            " [ 100  280]]\n",
            "\n",
            "\n",
            "Prediction:\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM**\n"
      ],
      "metadata": {
        "id": "AYbIdHUPXTZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM with Word N-Gram**"
      ],
      "metadata": {
        "id": "vgzkfxoPbzOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "cv = CountVectorizer(analyzer = 'word',ngram_range=(1,1), stop_words='english')\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)"
      ],
      "metadata": {
        "id": "yqPtrL06b7KF"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc = LinearSVC()\n",
        "svc.fit(X_train_cv, y_train)\n",
        "# create predictions\n",
        "y_pred = svc.predict(X_test_cv)\n",
        "\n",
        "# find f-1 score\n",
        "score = f1_score(y_test, y_pred, average='micro')\n",
        "print('F-1 score : {}'.format(np.round(score,4)))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "test_text=cv.transform([\"tambuk siapa nyawa ngini\"])\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Prediction:\")\n",
        "print(svc.predict(test_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkiOB_oNb7Qk",
        "outputId": "7837e247-d708-43fb-8404-f05f524af2bf"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-1 score : 0.8983\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.94      2697\n",
            "           1       0.61      0.48      0.54       380\n",
            "\n",
            "    accuracy                           0.90      3077\n",
            "   macro avg       0.77      0.72      0.74      3077\n",
            "weighted avg       0.89      0.90      0.89      3077\n",
            "\n",
            "confusion matrix:\n",
            "[[2582  115]\n",
            " [ 198  182]]\n",
            "\n",
            "\n",
            "Prediction:\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM with TF-IDF**"
      ],
      "metadata": {
        "id": "F-jqP5EIXfPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TFIDF\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_train = tfidf.fit_transform(X_train)\n",
        "#Fitting and transforming input data\n",
        "tfidf_train = tfidf.transform(X_train)\n",
        "tfidf_test = tfidf.transform(X_test)"
      ],
      "metadata": {
        "id": "ebC6y7anXa8X"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train svm\n",
        "svc = LinearSVC()\n",
        "svc.fit(tfidf_train, y_train)#TFIDF\n",
        "\n",
        "y_pred = svc.predict(tfidf_test)\n",
        "\n",
        "# find f-1 score\n",
        "score = f1_score(y_test, y_pred, average='micro')\n",
        "print('F-1 score : {}'.format(np.round(score,4)))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "test_text=tfidf.transform([\"tambuk siapa nyawa ngini\"])\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Prediction:\")\n",
        "print(svc.predict(test_text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh1DzGb6XbFu",
        "outputId": "94fa72a2-e668-4f2a-ecf0-fb50b9b5ec2c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-1 score : 0.9106\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95      2697\n",
            "           1       0.75      0.42      0.54       380\n",
            "\n",
            "    accuracy                           0.91      3077\n",
            "   macro avg       0.83      0.70      0.74      3077\n",
            "weighted avg       0.90      0.91      0.90      3077\n",
            "\n",
            "confusion matrix:\n",
            "[[2643   54]\n",
            " [ 221  159]]\n",
            "\n",
            "\n",
            "Prediction:\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM with Word N-Gram and TF-IDF**"
      ],
      "metadata": {
        "id": "blBqiQSwgCnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tfidf = TfidfVectorizer(min_df=5, ngram_range=(1, 1))\n",
        "tfidf_features = Tfidf.fit_transform(df['Text'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, df[\"Label\"], test_size = 1/5, random_state = 50)"
      ],
      "metadata": {
        "id": "UT-tcMFEgDpt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train svm\n",
        "svc = LinearSVC()\n",
        "svc.fit(X_train, y_train)#TFIDF\n",
        "\n",
        "y_pred = svc.predict(X_test)\n",
        "\n",
        "# find f-1 score\n",
        "score = f1_score(y_test, y_pred, average='micro')\n",
        "print('F-1 score : {}'.format(np.round(score,4)))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "test_text=Tfidf.transform([\"bungul siapa nyawa ngini\"])\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Prediction:\")\n",
        "print(svc.predict(test_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7AwBx1LgDvz",
        "outputId": "d2be0723-b584-4fee-9353-d5bff94f4d96"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-1 score : 0.9032\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.95      2657\n",
            "           1       0.79      0.40      0.53       420\n",
            "\n",
            "    accuracy                           0.90      3077\n",
            "   macro avg       0.85      0.69      0.74      3077\n",
            "weighted avg       0.89      0.90      0.89      3077\n",
            "\n",
            "confusion matrix:\n",
            "[[2613   44]\n",
            " [ 254  166]]\n",
            "\n",
            "\n",
            "Prediction:\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM with Word2Vec**"
      ],
      "metadata": {
        "id": "L6mztcMa21w-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Label'], test_size=0.2, random_state=42)\n",
        "w2v_model = gensim.models.Word2Vec(X_train, vector_size=100, window=5, min_count=5, workers=4)\n",
        "\n",
        "w2v_model.wv.index_to_key\n",
        "\n",
        "words = set(w2v_model.wv.index_to_key)\n",
        "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
        "                         for ls in X_train])\n",
        "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
        "                         for ls in X_test])\n",
        "\n",
        "# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n",
        "X_train_vect_avg = []\n",
        "for v in X_train_vect:\n",
        "    if v.size:\n",
        "        X_train_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
        "        \n",
        "X_test_vect_avg = []\n",
        "for v in X_test_vect:\n",
        "    if v.size:\n",
        "        X_test_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_test_vect_avg.append(np.zeros(100, dtype=float))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd4d1556-fb26-4be4-8ea3-9d21c2d25c83",
        "id": "1200wcyK2Uw0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train svm\n",
        "svc = LinearSVC()\n",
        "svc.fit(X_train_vect_avg, y_train.values)\n",
        "\n",
        "y_pred = svc.predict(X_test_vect_avg)\n",
        "\n",
        "# find f-1 score\n",
        "score = f1_score(y_test, y_pred, average='micro')\n",
        "print('F-1 score : {}'.format(np.round(score,4)))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "test_text=([\"tambuk siapa nyawa ngini\"])\n",
        "test_text_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
        "                         for ls in test_text])\n",
        "test_text_avg = []\n",
        "for v in test_text_vect:\n",
        "    if v.size:\n",
        "        test_text_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        test_text_avg.append(np.zeros(100, dtype=float))\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Prediction:\")\n",
        "print(svc.predict(test_text_avg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYWhjeUB2aTW",
        "outputId": "8fb7a8ad-6701-43aa-f7cb-bf741d3f64a9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-1 score : 0.8804\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94      2697\n",
            "           1       0.93      0.03      0.07       380\n",
            "\n",
            "    accuracy                           0.88      3077\n",
            "   macro avg       0.90      0.52      0.50      3077\n",
            "weighted avg       0.89      0.88      0.83      3077\n",
            "\n",
            "confusion matrix:\n",
            "[[2696    1]\n",
            " [ 367   13]]\n",
            "\n",
            "\n",
            "Prediction:\n",
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM with Glove**"
      ],
      "metadata": {
        "id": "y7yS345tPmbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "g = GloveVectorizer()\n",
        "svm = LinearSVC()\n",
        "\n",
        "pipeline = make_pipeline(g, svm)\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "score = f1_score(y_test, y_pred, average='micro')\n",
        "print('F-1 score : {}'.format(np.round(score,4)))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion matrix:\")\n",
        "\n",
        "print(metrics.confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAQfBzxSPp42",
        "outputId": "198efce8-d0a2-4f4b-a052-fe5dddc2b962"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-1 score : 0.8729\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.99      0.93      2697\n",
            "           1       0.33      0.02      0.04       380\n",
            "           2       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.87      3077\n",
            "   macro avg       0.40      0.34      0.32      3077\n",
            "weighted avg       0.81      0.87      0.82      3077\n",
            "\n",
            "confusion matrix:\n",
            "[[2678   16    3]\n",
            " [ 372    8    0]\n",
            " [   0    0    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision Tree**\n"
      ],
      "metadata": {
        "id": "52Lw3CCyiEip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree with word N-Gram**"
      ],
      "metadata": {
        "id": "sE0LXeuVjTkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "cv = CountVectorizer(analyzer = 'word',ngram_range=(1,5), stop_words='english')\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)"
      ],
      "metadata": {
        "id": "w9bHO3zhjaoh"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train_cv, y_train)\n",
        "# create predictions\n",
        "y_pred = dt.predict(X_test_cv)\n",
        "\n",
        "# find f-1 score\n",
        "score = f1_score(y_test, y_pred, average='micro')\n",
        "print('F-1 score : {}'.format(np.round(score,4)))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "test_text=cv.transform([\"tambuk siapa nyawa ngini\"])\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Prediction:\")\n",
        "print(dt.predict(test_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYteeXCPjaxE",
        "outputId": "7b0161f0-9db2-496c-c25d-22c4317389b0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-1 score : 0.8947\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.94      2697\n",
            "           1       0.59      0.46      0.52       380\n",
            "\n",
            "    accuracy                           0.89      3077\n",
            "   macro avg       0.76      0.71      0.73      3077\n",
            "weighted avg       0.89      0.89      0.89      3077\n",
            "\n",
            "confusion matrix:\n",
            "[[2577  120]\n",
            " [ 204  176]]\n",
            "\n",
            "\n",
            "Prediction:\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree with TF-IDF**"
      ],
      "metadata": {
        "id": "ei0FepEnkRCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TFIDF\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_train = tfidf.fit_transform(X_train)\n",
        "#Fitting and transforming input data\n",
        "tfidf_train = tfidf.transform(X_train)\n",
        "tfidf_test = tfidf.transform(X_test)"
      ],
      "metadata": {
        "id": "YhomFyKDknv_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(tfidf_train, y_train)\n",
        "# create predictions\n",
        "y_pred = dt.predict(tfidf_test)\n",
        "\n",
        "# find f-1 score\n",
        "score = f1_score(y_test, y_pred, average='micro')\n",
        "print('F-1 score : {}'.format(np.round(score,4)))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "test_text=tfidf.transform([\"tambuk siapa nyawa ngini\"])\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Prediction:\")\n",
        "print(dt.predict(test_text))"
      ],
      "metadata": {
        "id": "IvR0dzwmkn4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28672ef4-14ce-465f-8002-16fb81594f83"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-1 score : 0.8833\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.93      2697\n",
            "           1       0.53      0.46      0.50       380\n",
            "\n",
            "    accuracy                           0.88      3077\n",
            "   macro avg       0.73      0.70      0.71      3077\n",
            "weighted avg       0.88      0.88      0.88      3077\n",
            "\n",
            "confusion matrix:\n",
            "[[2542  155]\n",
            " [ 204  176]]\n",
            "\n",
            "\n",
            "Prediction:\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree with Word N-Gram and TF-IDF**"
      ],
      "metadata": {
        "id": "s_h1lUVjk5K1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tfidf = TfidfVectorizer(min_df=5, ngram_range=(1, 5))\n",
        "tfidf_features = Tfidf.fit_transform(df.Text)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, df[\"Label\"], test_size = 1/5, random_state = 50)"
      ],
      "metadata": {
        "id": "swp27rz1lGN_"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "# create predictions\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# find f-1 score\n",
        "score = f1_score(y_test, y_pred, average='micro')\n",
        "print('F-1 score : {}'.format(np.round(score,4)))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "test_text=tfidf.fit_transform([\"tambuk siapa nyawa ngini\"])\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Prediction:\")\n",
        "print(dt.predict(test_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "jqEktON9lGjW",
        "outputId": "c63a99ee-afe2-454f-f4f7-31871f1e5ee5"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-1 score : 0.8707\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.93      2657\n",
            "           1       0.53      0.49      0.51       420\n",
            "\n",
            "    accuracy                           0.87      3077\n",
            "   macro avg       0.72      0.71      0.72      3077\n",
            "weighted avg       0.87      0.87      0.87      3077\n",
            "\n",
            "confusion matrix:\n",
            "[[2475  182]\n",
            " [ 216  204]]\n",
            "\n",
            "\n",
            "Prediction:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-38baa3598bc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[1;32m    466\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             if issparse(X) and (\n\u001b[1;32m    435\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: X has 4 features, but DecisionTreeClassifier is expecting 6119 features as input."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree with Word2Vec**"
      ],
      "metadata": {
        "id": "MNiK91QJ28p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "w2v_model = gensim.models.Word2Vec(X_train, vector_size=100, window=5, min_count=2)\n",
        "\n",
        "words = set(w2v_model.wv.index_to_key )\n",
        "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
        "                         for ls in X_train])\n",
        "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
        "                         for ls in X_test])\n",
        "\n",
        "# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n",
        "X_train_vect_avg = []\n",
        "for v in X_train_vect:\n",
        "    if v.size:\n",
        "        X_train_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
        "        \n",
        "X_test_vect_avg = []\n",
        "for v in X_test_vect:\n",
        "    if v.size:\n",
        "        X_test_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_test_vect_avg.append(np.zeros(100, dtype=float))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fddd8a4e-7159-4cbf-8ea0-8cff4329cde4",
        "id": "nabxZF6Y28p6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train_vect_avg, y_train)\n",
        "\n",
        "y_pred = dt.predict(X_test_vect_avg)\n",
        "\n",
        "# find f-1 score\n",
        "score = f1_score(y_test, y_pred, average='micro')\n",
        "print('F-1 score : {}'.format(np.round(score,4)))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38f9f926-3e67-4db7-f15d-e274f840730d",
        "id": "o_w9xW1I28p7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-1 score : 0.7751\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.85      0.87      2697\n",
            "           1       0.19      0.24      0.21       380\n",
            "\n",
            "    accuracy                           0.78      3077\n",
            "   macro avg       0.54      0.55      0.54      3077\n",
            "weighted avg       0.80      0.78      0.79      3077\n",
            "\n",
            "confusion matrix:\n",
            "[[2293  404]\n",
            " [ 288   92]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree with Glove**"
      ],
      "metadata": {
        "id": "VyQ7rEoVQJQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "g = GloveVectorizer()\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "pipeline = make_pipeline(g, dt)\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "score = f1_score(y_test, y_pred, average='micro')\n",
        "print('F-1 score : {}'.format(np.round(score,4)))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oC0nBR7QLUU",
        "outputId": "d6bd099c-39b1-40e3-a2b4-c57ed93adbd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-1 score : 0.7888\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88      2697\n",
            "           1       0.16      0.17      0.16       380\n",
            "\n",
            "    accuracy                           0.79      3077\n",
            "   macro avg       0.52      0.52      0.52      3077\n",
            "weighted avg       0.79      0.79      0.79      3077\n",
            "\n",
            "confusion matrix:\n",
            "[[2363  334]\n",
            " [ 316   64]]\n"
          ]
        }
      ]
    }
  ]
}